{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophelanternier/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from public_auc_veolia2 import score_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "\n",
    "INPUT_TRAIN = DATA_PATH+'input_train.csv'\n",
    "OUTPUT_TRAIN = DATA_PATH+'output_train.csv'\n",
    "INPUT_SUBMISSION = DATA_PATH+'input_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_train = pd.read_csv(INPUT_TRAIN,index_col='Id')\n",
    "output_train = pd.read_csv(OUTPUT_TRAIN,sep=';',index_col='Id')\n",
    "input_submission = pd.read_csv(INPUT_SUBMISSION ,index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19427, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the rows with a canalisation breaks\n",
    "ID_2014 = output_train[output_train['2014']==1].index.tolist()\n",
    "ID_2015 = output_train[output_train['2015']==1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of breaks in 2014: (53, 7)\n",
      "Dimension of breaks in 2015: (37, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of breaks in 2014: {0}\".format(input_train.iloc[ID_2014].shape))\n",
    "print(\"Dimension of breaks in 2015: {0}\".format(input_train.iloc[ID_2015].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to preprocess before splitting into test and train data because get_dummies will only take into account existing categories, thus there are less columns in the test set if we preprocess after splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(dataframe,year=2014, more_features = False):\n",
    "    X = dataframe\n",
    "    \n",
    "    # The relevant value is the age of the pipes\n",
    "    X['Age'] = year - X['YearConstruction']\n",
    "    X = X.fillna(10000)\n",
    "    \n",
    "    # How long has it been since last failure\n",
    "    X['YearsOldLastFailure'] = year - X['YearLastFailureObserved']\n",
    "\n",
    "    # Categorical data\n",
    "    X = pd.concat([X,pd.get_dummies(X['Feature1'])],axis=1)\n",
    "    X = pd.concat([X,pd.get_dummies(X['Feature2'])],axis=1)\n",
    "    X = pd.concat([X,pd.get_dummies(X['Feature4'])],axis=1)\n",
    "    \n",
    "    X = X.drop([\"YearConstruction\",\"YearLastFailureObserved\",\"Feature1\",\"Feature2\",\"Feature4\"],axis=1)\n",
    "   \n",
    "    X['Feature3'] = normalize(X['Feature3']).tolist()[0]\n",
    "    X['Length'] = normalize(X['Length']).tolist()[0]\n",
    "    X['Age'] = normalize(X['Age']).tolist()[0]\n",
    "    X['YearsOldLastFailure'] = normalize(X['YearsOldLastFailure']).tolist()[0]\n",
    "    \n",
    "    if more_features:\n",
    "        col = X.columns[4:]\n",
    "        for c in col:\n",
    "            for u in col:\n",
    "                X[c+u] = X[c]*X[u]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_train = preprocess(input_train,year = 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perc = 0.4\n",
    "perc2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ids_2014 = [ID_2014[w] for w in np.random.randint(0,high=len(ID_2014),size=int(perc*len(ID_2014)))] + np.random.randint(0,high=input_train.shape[0],size=int(perc2*len(ID_2014))).tolist()\n",
    "test_ids_2015 = [ID_2015[w] for w in np.random.randint(0,high=len(ID_2015),size=int(perc*len(ID_2015)))] + np.random.randint(0,high=input_train.shape[0],size=int(perc2*len(ID_2015))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repartition: \n",
      "2015:  17\n",
      "2014:  23\n",
      "Not Broken:  897\n"
     ]
    }
   ],
   "source": [
    "input_test = pd.concat([input_train.loc[test_ids_2014],input_train.loc[test_ids_2015]])\n",
    "output_test = pd.concat([output_train.loc[test_ids_2014],output_train.loc[test_ids_2015]])\n",
    "\n",
    "print \"Repartition: \"\n",
    "print \"2015: \", output_test[output_test['2015'] == 1].shape[0]\n",
    "print \"2014: \", output_test[output_test['2014'] == 1].shape[0]\n",
    "print \"Not Broken: \", output_test[~((output_test['2014'] == 1) | (output_test['2015'] == 1))].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_2014_train = [w for w in ID_2014 if w not in test_ids_2014]\n",
    "ID_2015_train = [w for w in ID_2015 if w not in test_ids_2015]\n",
    "ID_train = [w for w in output_train.index if w not in (test_ids_2014 + test_ids_2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Augment data with breaks to counter unbalanced dataset only for training\n",
    "REPETITIONS = 7\n",
    "for k in range(0,REPETITIONS):\n",
    "    input_train = pd.concat([input_train.loc[ID_2014_train],input_train.loc[ID_2015_train],input_train.loc[ID_train]])\n",
    "    output_train = pd.concat([output_train.loc[ID_2014_train],output_train.loc[ID_2015_train],output_train.loc[ID_train]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((27570, 13), (27570, 2))\n",
      "((935, 13), (935, 2))\n"
     ]
    }
   ],
   "source": [
    "print(input_train.shape, output_train.shape)\n",
    "print(input_test.shape, output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_output(dataframe,year=2014):\n",
    "    '''\n",
    "    Selects the right colum for the year studied\n",
    "    '''\n",
    "    return dataframe[str(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86       912\n",
      "          1       0.08      0.87      0.15        23\n",
      "\n",
      "avg / total       0.97      0.76      0.84       935\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.79      0.88       918\n",
      "          1       0.06      0.71      0.11        17\n",
      "\n",
      "avg / total       0.98      0.79      0.86       935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2014\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "logreg_1 = LogisticRegression(class_weight='balanced')\n",
    "logreg_1.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = logreg_1.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,y_pred))\n",
    "\n",
    "YEAR = 2015\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test_2 = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "logreg_2 = LogisticRegression(class_weight='balanced')\n",
    "logreg_2.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_2 = logreg_2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test_2,y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = np.array([y_pred,y_pred_2]).T\n",
    "true = np.array([Y_test,Y_test_2]).T\n",
    "\n",
    "print(score_function(pred,true))\n",
    "print('Votre score est de : 0.76149277963129')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YEAR = 2014\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "logreg_1 = SVC()\n",
    "logreg_1.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = logreg_1.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,y_pred))\n",
    "\n",
    "YEAR = 2015\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test_2 = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "logreg_2 = SVC()\n",
    "logreg_2.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_2 = logreg_2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test_2,y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = np.array([y_pred,y_pred_2]).T\n",
    "true = np.array([Y_test,Y_test_2]).T\n",
    "\n",
    "print(score_function(pred,true))\n",
    "print('Votre score est de : 0.76149277963129')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions for the submission data\n",
    "#sub_1 = logreg_1.predict(preprocess(input_submission,year=2015))\n",
    "#sub_2 = logreg_2.predict(preprocess(input_submission,year=2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submission formating\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = input_submission.index.tolist()\n",
    "submission['2014'] = sub_1[:]\n",
    "submission['2015'] = sub_2[:]\n",
    "submission = submission.set_index('Id')\n",
    "submission.to_csv('../submissions/with_augmentation_aftersplit.csv',index=True,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# With adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 2014\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "rdm_1 = AdaBoostClassifier(n_estimators=100)\n",
    "rdm_1.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rdm_1.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YEAR = 2015\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "rdm_2 = AdaBoostClassifier(n_estimators=100)\n",
    "rdm_2.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rdm_2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array([y_pred,y_pred_2]).T\n",
    "true = np.array([Y_test,Y_test_2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_function(pred,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions for the submission data\n",
    "sub_1 = rdm_2015.predict_proba(preprocess(input_test,year=2014))\n",
    "sub_2 = rdm_2015.predict_proba(preprocess(input_test,year=2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission formating\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = input_test.index.tolist()\n",
    "submission['2014'] = sub_1[:,1]\n",
    "submission['2015'] = sub_2[:,1]\n",
    "submission = submission.set_index('Id')\n",
    "submission.to_csv('../submissions/data_augmentation_ada.csv',index=True,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier(n_estimators=10, max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       909\n",
      "          1       1.00      0.12      0.21        26\n",
      "\n",
      "avg / total       0.98      0.98      0.97       935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2014\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "rdm_1 = GBC\n",
    "rdm_1.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rdm_1.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       916\n",
      "          1       0.33      0.05      0.09        19\n",
      "\n",
      "avg / total       0.97      0.98      0.97       935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2015\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test_2 = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "rdm_2 = GBC\n",
    "rdm_2.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_2 = rdm_2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test_2,y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554005722460658"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([y_pred,y_pred_2]).T\n",
    "true = np.array([Y_test,Y_test_2]).T\n",
    "\n",
    "score_function(pred,true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=10, max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       912\n",
      "          1       1.00      0.04      0.08        23\n",
      "\n",
      "avg / total       0.98      0.98      0.97       935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2014\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "rdm_1 = RFC\n",
    "rdm_1.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rdm_1.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       918\n",
      "          1       0.80      0.24      0.36        17\n",
      "\n",
      "avg / total       0.98      0.99      0.98       935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2015\n",
    "\n",
    "X_train = input_train\n",
    "Y_train = preprocess_output(output_train, year = YEAR)\n",
    "X_test = input_test\n",
    "Y_test_2 = preprocess_output(output_test, year = YEAR)\n",
    "\n",
    "rdm_2 = RFC\n",
    "rdm_2.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_2 = rdm_2.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test_2,y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95013791991895191"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([y_pred,y_pred_2]).T\n",
    "true = np.array([Y_test,Y_test_2]).T\n",
    "\n",
    "score_function(pred,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions for the submission data\n",
    "sub_1 = rdm_1.predict_proba(preprocess(input_submission,year=2014))\n",
    "sub_2 = rdm_2.predict_proba(preprocess(input_submission,year=2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission formating\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = input_submission.index.tolist()\n",
    "submission['2014'] = sub_1[:,1]\n",
    "submission['2015'] = sub_2[:,1]\n",
    "submission = submission.set_index('Id')\n",
    "submission.to_csv('../submissions/data_augmentation_rfc.csv',index=True,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
