{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of breaks in 2014: (53, 7)\n",
      "Dimension of breaks in 2015: (37, 7)\n",
      "(88, 94) (88, 2)\n",
      "(32769, 94) (32769, 2)\n",
      "(88, 94) (88, 2)\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "INPUT_TRAIN = DATA_PATH+'input_train.csv'\n",
    "OUTPUT_TRAIN = DATA_PATH+'output_train.csv'\n",
    "INPUT_SUBMISSION = DATA_PATH+'input_test.csv'\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "input_train = pd.read_csv(INPUT_TRAIN,index_col='Id')\n",
    "output_train = pd.read_csv(OUTPUT_TRAIN,sep=';',index_col='Id')\n",
    "input_submission = pd.read_csv(INPUT_SUBMISSION ,index_col='Id')\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "input_train.shape\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "# Select the rows with a canalisation breaks\n",
    "ID_2014 = output_train[output_train['2014']==1].index.tolist()\n",
    "ID_2015 = output_train[output_train['2015']==1].index.tolist()\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "print(\"Dimension of breaks in 2014: {0}\".format(input_train.iloc[ID_2014].shape))\n",
    "print(\"Dimension of breaks in 2015: {0}\".format(input_train.iloc[ID_2015].shape))\n",
    "\n",
    "\n",
    "#  We need to preprocess before splitting into test and train data because get_dummies will only take into account existing categories, thus there are less columns in the test set if we preprocess after splitting.\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "def preprocess(dataframe,year=2014):\n",
    "    X = dataframe\n",
    "    \n",
    "    # The relevant value is the age of the pipes\n",
    "    X['Age'] = year - X['YearConstruction']\n",
    "    X = X.fillna(10000)\n",
    "    \n",
    "    # How long has it been since last failure\n",
    "    X['YearsOldLastFailure'] = year - X['YearLastFailureObserved']\n",
    "\n",
    "    # Categorical data\n",
    "    X = pd.concat([X,pd.get_dummies(X['Feature1'])],axis=1)\n",
    "    X = pd.concat([X,pd.get_dummies(X['Feature2'])],axis=1)\n",
    "    X = pd.concat([X,pd.get_dummies(X['Feature4'])],axis=1)\n",
    "    \n",
    "    X = X.drop([\"YearConstruction\",\"YearLastFailureObserved\",\"Feature1\",\"Feature2\",\"Feature4\"],axis=1)\n",
    "   \n",
    "    X['Feature3'] = normalize(X['Feature3']).tolist()[0]\n",
    "    X['Length'] = normalize(X['Length']).tolist()[0]\n",
    "    X['Age'] = normalize(X['Age']).tolist()[0]\n",
    "    X['YearsOldLastFailure'] = normalize(X['YearsOldLastFailure']).tolist()[0]\n",
    "     \n",
    "    col = X.columns[4:]\n",
    "    for c in col:\n",
    "        for u in col:\n",
    "            X[c+u] = X[c]*X[u]\n",
    "    return X\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "input_train = preprocess(input_train,year = 2015)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "perc = 0.5\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "test_ids_2014 = [ID_2014[w] for w in np.random.randint(0,high=len(ID_2014),size=int(perc*len(ID_2014)))] + np.random.randint(0,high=input_train.shape[0],size=int(perc*len(ID_2014))).tolist()\n",
    "test_ids_2015 = [ID_2015[w] for w in np.random.randint(0,high=len(ID_2015),size=int(perc*len(ID_2015)))] + np.random.randint(0,high=input_train.shape[0],size=int(perc*len(ID_2015))).tolist()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "input_test = pd.concat([input_train.loc[test_ids_2014],input_train.loc[test_ids_2015]])\n",
    "output_test = pd.concat([output_train.loc[test_ids_2014],output_train.loc[test_ids_2015]])\n",
    "\n",
    "print(input_test.shape,output_test.shape)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "ID_2014_train = [w for w in ID_2014 if w not in test_ids_2014]\n",
    "ID_2015_train = [w for w in ID_2015 if w not in test_ids_2015]\n",
    "ID_train = [w for w in output_train.index if w not in (test_ids_2014 + test_ids_2015)]\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "# Augment data with breaks to counter unbalanced dataset only for training\n",
    "REPETITIONS = 7\n",
    "for k in range(0,REPETITIONS):\n",
    "    input_train = pd.concat([input_train.loc[ID_2014_train],input_train.loc[ID_2015_train],input_train.loc[ID_train]])\n",
    "    output_train = pd.concat([output_train.loc[ID_2014_train],output_train.loc[ID_2015_train],output_train.loc[ID_train]])\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "print(input_train.shape, output_train.shape)\n",
    "print(input_test.shape, output_test.shape)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "def preprocess_output(dataframe,year=2014):\n",
    "    '''\n",
    "    Selects the right colum for the year studied\n",
    "    '''\n",
    "    return dataframe[str(year)]\n",
    "\n",
    "\n",
    "# In[28]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 94)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(94,)))\n",
    "model.add(Dense(1000))\n",
    "model.add(Dense(1000))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "sgd = SGD(lr = 0.0001,momentum=0.9,decay=0.01)\n",
    "model.compile(optimizer='rmsprop',\n",
    "      loss='mse',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 94)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32769 samples, validate on 88 samples\n",
      "Epoch 1/100\n",
      "32064/32769 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.5586"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(input_train),np.array(output_train),validation_data=(np.array(input_test),np.array(output_test)),nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
